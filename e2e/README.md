# E2E Testing Strategy

## Testing Objective

The E2E test suite validates the AI Library Manager application's functionality from a user's perspective, ensuring:

1. **Functional Correctness**: All features work as expected across the full stack
2. **Integration Integrity**: Frontend, API, and database components work together correctly
3. **User Experience**: UI interactions, navigation, and feedback work properly
4. **Regression Prevention**: Changes don't break existing functionality

## Testing Approach

### Dual-Mode Testing (Mock/Live)

AI-dependent tests support two modes to balance reliability with real-world validation:

| Mode | When to Use | Speed | Reliability | Cost |
|------|-------------|-------|-------------|------|
| **Mock** (default) | CI/CD, local dev, PR checks | Fast (~3 min) | 100% deterministic | Free |
| **Live** | Pre-production, nightly runs | Slower (~10 min) | Variable (API dependent) | API costs |

```bash
# Run in mock mode (default)
npm run test:e2e

# Run in live mode (hits real AI API)
npm run test:e2e:live

# Record new mock data
npm run test:e2e:record
```

### Page Object Model

Tests use the `LibraryPage` class ([fixtures.ts](./fixtures.ts)) to encapsulate page interactions:

```typescript
const libraryPage = new LibraryPage(page);
await libraryPage.goto();
await libraryPage.selectBook('Deep Learning');
await libraryPage.sendChatMessage('What is this book about?');
```

## Tools & Technologies

| Tool | Purpose |
|------|---------|
| **Playwright** | Browser automation & testing framework |
| **TypeScript** | Type-safe test code |
| **Chromium** | Default browser for tests |
| **HAR Files** | Recording/replay of network requests for AI mocking |

### Key Playwright Features Used

- `page.route()` - API mocking/interception
- `page.routeFromHAR()` - HAR-based response replay
- `expect().toBeVisible()` - Visibility assertions
- `page.waitForSelector()` - Dynamic content waiting
- `test.beforeEach()` - Test data setup

## Test Environment

### Prerequisites

- Node.js 18+
- Local server running on port 3000
- SQLite database (auto-created)

### Configuration

**[playwright.config.ts](../playwright.config.ts)**
- Browser: Chromium (headless by default)
- Base URL: `http://localhost:3000`
- Timeout: 60 seconds per test
- Retries: 0 in development, configurable for CI
- Web server auto-start enabled

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `AI_TEST_MODE` | `mock` | `mock` or `live` - controls AI API mocking |
| `RECORD_HAR` | `false` | Set to `true` to record AI responses |
| `CI` | - | Detected automatically in CI environments |

## Test Coverage Scope

### Test Suites (171 tests total)

| Suite | File | Tests | Coverage |
|-------|------|-------|----------|
| **AI Chat** | `ai-chat.spec.ts` | 24 | Chat UI, messaging, AI responses, context management |
| **API Endpoints** | `api.spec.ts` | 34 | REST API validation for all endpoints |
| **Book Management** | `book-management.spec.ts` | 19 | Add, view, edit, delete books |
| **Navigation & History** | `navigation-history.spec.ts` | 19 | Panel navigation, history tracking |
| **Q&A Management** | `qa-management.spec.ts` | 11 | Save, display, hide/unhide Q&A |
| **Search & Filter** | `search-filter.spec.ts` | 20 | Full-text search, filters, sorting |
| **Settings** | `settings.spec.ts` | 23 | Settings modal, taxonomy editor |
| **Taxonomy** | `taxonomy.spec.ts` | 21 | Genre dropdown, filtering, API |

### Coverage Areas

#### UI Components
- ✅ Header & statistics
- ✅ Book grid & cards
- ✅ Book detail panel
- ✅ Chat panel
- ✅ Settings modal
- ✅ Genre dropdown
- ✅ Add book modal

#### User Flows
- ✅ Browse and select books
- ✅ Add new books
- ✅ Search and filter library
- ✅ Chat with AI assistant
- ✅ Navigate book history
- ✅ Manage saved Q&A
- ✅ Configure taxonomy

#### API Endpoints
- ✅ Health check
- ✅ Books CRUD
- ✅ Notes management
- ✅ Search
- ✅ Q&A operations
- ✅ Statistics
- ✅ Taxonomy management
- ✅ AI query/clear

## Directory Structure

```
e2e/
├── fixtures.ts           # Page object model & test setup
├── helpers/
│   └── ai-mock.ts        # AI mocking infrastructure
├── fixtures/
│   └── ai-responses/     # HAR files for AI mocking
│       └── ai-api.har    # (Generated by recording)
├── ai-chat.spec.ts       # AI chat tests
├── api.spec.ts           # API endpoint tests
├── book-management.spec.ts
├── navigation-history.spec.ts
├── qa-management.spec.ts
├── search-filter.spec.ts
├── settings.spec.ts
├── taxonomy.spec.ts
├── AI_MOCK_STRATEGY.md   # Detailed AI mocking documentation
└── README.md             # This file
```

## Running Tests

### Commands

```bash
# Run all tests in mock mode (default, fast)
npm run test:e2e

# Run in live mode (real AI API)
npm run test:e2e:live

# Run with UI for debugging
npm run test:e2e:ui

# Run headed (see browser)
npm run test:e2e:headed

# View test report
npm run test:e2e:report

# Run specific test file
npx playwright test e2e/ai-chat.spec.ts

# Run tests matching pattern
npx playwright test --grep "should add"
```

### CI/CD Integration

```yaml
# Example GitHub Actions workflow
jobs:
  e2e-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npx playwright install --with-deps
      - run: npm run test:e2e  # Uses mock mode

  # Optional: live validation on main branch
  e2e-live:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npx playwright install --with-deps
      - run: npm run test:e2e:live
    env:
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
```

## Best Practices

### Writing Tests

1. **Use page object methods** from `LibraryPage` class
2. **Wait for state changes** instead of fixed timeouts
3. **Use semantic selectors** (text, role) over CSS classes
4. **Test isolation**: Each test sets up its own data
5. **Clean assertions**: One logical assertion per test

### AI-Dependent Tests

1. **Use dynamic timeouts** from `ai-mock.ts`
2. **Mock responses** match real API format
3. **Test behavior**, not AI content
4. **Record HAR files** periodically to keep mocks current

### Debugging

1. **Run with UI**: `npm run test:e2e:ui`
2. **Check screenshots**: `test-results/*/test-failed-*.png`
3. **Watch videos**: `test-results/*/video.webm`
4. **Read error context**: `test-results/*/error-context.md`

## Maintenance

### Adding New Tests

1. Choose appropriate spec file or create new one
2. Use `LibraryPage` methods for interactions
3. For AI tests, use timeouts from `ai-mock.ts`
4. Run locally in both mock and live modes

### Updating AI Mocks

```bash
# When AI behavior changes, refresh the HAR file
AI_TEST_MODE=live RECORD_HAR=true npx playwright test --grep @ai
```

### Troubleshooting

| Issue | Solution |
|-------|----------|
| Tests timeout | Check if server is running on port 3000 |
| AI tests fail in mock mode | Verify HAR file exists or fallback mocks work |
| Flaky tests | Add proper waits, avoid fixed timeouts |
| Selector not found | Check if element has correct class/text |
